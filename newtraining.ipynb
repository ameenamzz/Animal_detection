{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics roboflow -q\n",
    "\n",
    "# Import necessary libraries\n",
    "from ultralytics import YOLO\n",
    "from roboflow import Roboflow\n",
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import random\n",
    "import json\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Your Roboflow API key\n",
    "api_key = \"1VHz8QF5F69ddtGCCfTg\"\n",
    "\n",
    "# Function to download object detection dataset from Roboflow\n",
    "def download_detection_dataset(api_key, workspace, project_name, version, format_type=\"yolov8\", location=\"./datasets\"):\n",
    "    rf = Roboflow(api_key=api_key)\n",
    "    project = rf.workspace(workspace).project(project_name)\n",
    "    dataset = project.version(version).download(format_type, location=f\"{location}/{project_name}\")\n",
    "    return dataset, f\"{location}/{project_name}\"\n",
    "\n",
    "# Function to download classification dataset from Roboflow\n",
    "def download_classification_dataset(api_key, workspace, project_name, version, location=\"./datasets\"):\n",
    "    rf = Roboflow(api_key=api_key)\n",
    "    project = rf.workspace(workspace).project(project_name)\n",
    "    dataset = project.version(version).download(\"folder\", location=f\"{location}/{project_name}\")\n",
    "    return dataset, f\"{location}/{project_name}\"\n",
    "\n",
    "# Download the classification dataset\n",
    "print(\"Downloading Footprint Classification dataset...\")\n",
    "footprint_dataset, footprint_path = download_classification_dataset(\n",
    "    api_key=api_key,\n",
    "    workspace=\"sml-project-hfi0w\",\n",
    "    project_name=\"footprint-classification\",\n",
    "    version=1,\n",
    "    location=\"./footprint_dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Identify classes in the footprint classification dataset\n",
    "footprint_classes = []\n",
    "for class_dir in os.listdir(f\"{footprint_path}/train\"):\n",
    "    if os.path.isdir(f\"{footprint_path}/train/{class_dir}\"):\n",
    "        footprint_classes.append(class_dir)\n",
    "        \n",
    "print(f\"Footprint classification classes: {footprint_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Download all other detection datasets\n",
    "print(\"Downloading object detection datasets...\")\n",
    "\n",
    "# Dataset 2: Wild Animal Foot Prints\n",
    "dataset2, dataset2_path = download_detection_dataset(\n",
    "    api_key=api_key,\n",
    "    workspace=\"traffic-bfp0e\",\n",
    "    project_name=\"wild-animal-foot-prints\",\n",
    "    version=1,\n",
    "    location=\"./dataset2\"\n",
    ")\n",
    "\n",
    "# Dataset 3: Fred's Test\n",
    "dataset3, dataset3_path = download_detection_dataset(\n",
    "    api_key=api_key,\n",
    "    workspace=\"fredstest\",\n",
    "    project_name=\"othsgdsreq\",\n",
    "    version=38,\n",
    "    location=\"./dataset3\"\n",
    ")\n",
    "\n",
    "# Dataset 4: New Animal Detection\n",
    "dataset4, dataset4_path = download_detection_dataset(\n",
    "    api_key=api_key,\n",
    "    workspace=\"lavhini\",\n",
    "    project_name=\"new_animaldetection\",\n",
    "    version=1,\n",
    "    location=\"./dataset4\"\n",
    ")\n",
    "\n",
    "print(\"All datasets downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load class information from detection datasets\n",
    "def get_classes_from_yaml(yaml_path):\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    return data.get('names', [])\n",
    "\n",
    "dataset2_classes = get_classes_from_yaml(f\"{dataset2_path}/data.yaml\")\n",
    "dataset3_classes = get_classes_from_yaml(f\"{dataset3_path}/data.yaml\")\n",
    "dataset4_classes = get_classes_from_yaml(f\"{dataset4_path}/data.yaml\")\n",
    "\n",
    "print(f\"Dataset2 classes: {dataset2_classes}\")\n",
    "print(f\"Dataset3 classes: {dataset3_classes}\")\n",
    "print(f\"Dataset4 classes: {dataset4_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create directory structure for the combined dataset\n",
    "combined_dataset_path = \"./combined_dataset\"\n",
    "os.makedirs(combined_dataset_path, exist_ok=True)\n",
    "\n",
    "# Create train, val, test directories\n",
    "for dir_name in [\"train\", \"valid\", \"test\"]:\n",
    "    # Create images and labels directories in each split\n",
    "    for sub_dir in [\"images\", \"labels\"]:\n",
    "        os.makedirs(f\"{combined_dataset_path}/{dir_name}/{sub_dir}\", exist_ok=True)\n",
    "\n",
    "# Create a unified class list\n",
    "unified_classes = footprint_classes + dataset2_classes + dataset3_classes + dataset4_classes\n",
    "\n",
    "# Remove any duplicate class names\n",
    "unified_classes = list(dict.fromkeys(unified_classes))\n",
    "print(f\"Unified classes ({len(unified_classes)}): {unified_classes}\")\n",
    "\n",
    "# Create a mapping for class indices across different datasets\n",
    "class_mappings = {\n",
    "    \"footprint\": {i: unified_classes.index(footprint_classes[i]) for i in range(len(footprint_classes))},\n",
    "    \"dataset2\": {i: unified_classes.index(dataset2_classes[i]) for i in range(len(dataset2_classes))},\n",
    "    \"dataset3\": {i: unified_classes.index(dataset3_classes[i]) for i in range(len(dataset3_classes))},\n",
    "    \"dataset4\": {i: unified_classes.index(dataset4_classes[i]) for i in range(len(dataset4_classes))}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert classification images to object detection format\n",
    "def convert_classification_to_detection(image_path, label_id, output_img_path, output_label_path):\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return False\n",
    "    \n",
    "    height, width, _ = img.shape\n",
    "    \n",
    "    # Save image to output path\n",
    "    cv2.imwrite(output_img_path, img)\n",
    "    \n",
    "    # Create detection annotation (full image as bounding box)\n",
    "    # Format: class_id x_center y_center width height\n",
    "    # All normalized to [0, 1]\n",
    "    x_center, y_center = 0.5, 0.5  # Center of image\n",
    "    w, h = 1.0, 1.0  # Full image\n",
    "    \n",
    "    # Write label file\n",
    "    with open(output_label_path, 'w') as f:\n",
    "        f.write(f\"{label_id} {x_center} {y_center} {w} {h}\\n\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to process and remap label files for detection datasets\n",
    "def process_detection_label_file(src_file, dst_file, mapping):\n",
    "    with open(src_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    updated_lines = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) >= 5:  # Ensure proper format: class_id x y w h\n",
    "            class_id = int(parts[0])\n",
    "            if class_id in mapping:\n",
    "                parts[0] = str(mapping[class_id])\n",
    "                updated_lines.append(' '.join(parts) + '\\n')\n",
    "    \n",
    "    with open(dst_file, 'w') as f:\n",
    "        f.writelines(updated_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Process Footprint Classification dataset (convert to detection format)\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    split_dir = \"train\" if split == \"train\" else \"valid\" if split == \"valid\" else \"test\"\n",
    "    if not os.path.exists(f\"{footprint_path}/{split_dir}\"):\n",
    "        print(f\"Split {split_dir} not found in footprint dataset\")\n",
    "        continue\n",
    "        \n",
    "    # For each class folder\n",
    "    for class_idx, class_name in enumerate(footprint_classes):\n",
    "        class_dir = f\"{footprint_path}/{split_dir}/{class_name}\"\n",
    "        if not os.path.exists(class_dir):\n",
    "            continue\n",
    "            \n",
    "        # Process each image in the class\n",
    "        for img_file in glob.glob(f\"{class_dir}/*.jpg\") + glob.glob(f\"{class_dir}/*.jpeg\") + glob.glob(f\"{class_dir}/*.png\"):\n",
    "            img_filename = f\"footprint_{class_name}_{os.path.basename(img_file)}\"\n",
    "            out_img_path = f\"{combined_dataset_path}/{split}/images/{img_filename}\"\n",
    "            out_label_path = f\"{combined_dataset_path}/{split}/labels/{os.path.splitext(img_filename)[0]}.txt\"\n",
    "            \n",
    "            # Convert to detection format and save\n",
    "            mapped_class_id = class_mappings[\"footprint\"][class_idx]\n",
    "            convert_classification_to_detection(img_file, mapped_class_id, out_img_path, out_label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Process detection datasets\n",
    "dataset_paths = {\n",
    "    \"dataset2\": dataset2_path,\n",
    "    \"dataset3\": dataset3_path,\n",
    "    \"dataset4\": dataset4_path\n",
    "}\n",
    "\n",
    "# Function to combine detection datasets\n",
    "def combine_detection_datasets(dataset_path, dataset_key, split, class_mapping):\n",
    "    images_path = f\"{dataset_path}/{split}/images\"\n",
    "    labels_path = f\"{dataset_path}/{split}/labels\"\n",
    "    \n",
    "    if not os.path.exists(images_path) or not os.path.exists(labels_path):\n",
    "        print(f\"Skipping {dataset_key} {split} - directory not found\")\n",
    "        return\n",
    "    \n",
    "    # Process images\n",
    "    for img_file in glob.glob(f\"{images_path}/*\"):\n",
    "        img_filename = os.path.basename(img_file)\n",
    "        # Add dataset prefix to avoid filename conflicts\n",
    "        new_img_filename = f\"{dataset_key}_{img_filename}\"\n",
    "        shutil.copy(img_file, f\"{combined_dataset_path}/{split}/images/{new_img_filename}\")\n",
    "        \n",
    "        # Process corresponding label if it exists\n",
    "        label_filename = os.path.splitext(img_filename)[0] + \".txt\"\n",
    "        label_file = f\"{labels_path}/{label_filename}\"\n",
    "        if os.path.exists(label_file):\n",
    "            new_label_file = f\"{combined_dataset_path}/{split}/labels/{dataset_key}_{label_filename}\"\n",
    "            # Remap class IDs according to our unified class list\n",
    "            process_detection_label_file(label_file, new_label_file, class_mapping)\n",
    "\n",
    "# Combine all detection datasets\n",
    "for dataset_key, dataset_path in dataset_paths.items():\n",
    "    print(f\"Processing {dataset_key}...\")\n",
    "    for split in [\"train\", \"valid\", \"test\"]:\n",
    "        combine_detection_datasets(dataset_path, dataset_key, split, class_mappings[dataset_key])\n",
    "\n",
    "print(\"Datasets successfully combined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create YAML configuration file for the combined dataset\n",
    "yaml_content = {\n",
    "    'path': combined_dataset_path,\n",
    "    'train': 'train/images',\n",
    "    'val': 'valid/images',\n",
    "    'test': 'test/images',\n",
    "    'nc': len(unified_classes),\n",
    "    'names': unified_classes\n",
    "}\n",
    "\n",
    "# Write YAML file\n",
    "yaml_path = f\"{combined_dataset_path}/data.yaml\"\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(yaml_content, f, sort_keys=False)\n",
    "\n",
    "print(f\"Created data.yaml with {len(unified_classes)} classes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Train YOLOv8 model with the combined dataset\n",
    "# Load a pre-trained YOLOv8 model for transfer learning\n",
    "model = YOLO('yolov8n.pt')  # Use 'yolov8s.pt' or other variants for better performance\n",
    "\n",
    "# Set training parameters for optimal performance\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,  # Adjust based on your GPU memory\n",
    "    patience=10,\n",
    "    save_period=10,\n",
    "    device=0,  # Use GPU\n",
    "    workers=8,  # Adjust based on your CPU cores\n",
    "    pretrained=True,\n",
    "    optimizer='SGD',  # or 'Adam'\n",
    "    lr0=0.01,\n",
    "    lrf=0.01,\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=3.0,\n",
    "    warmup_momentum=0.8,\n",
    "    warmup_bias_lr=0.1,\n",
    "    box=7.5,\n",
    "    cls=0.5,\n",
    "    dfl=1.5,\n",
    "    fl_gamma=0.0,\n",
    "    label_smoothing=0.0,\n",
    "    nbs=64,\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7, \n",
    "    hsv_v=0.4,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    fliplr=0.5,\n",
    "    flipud=0.0,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.0,\n",
    "    copy_paste=0.0,\n",
    "    amp=True  # Use mixed precision for faster training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "metrics = model.val()\n",
    "print(f\"mAP50-95: {metrics.box.map}\")\n",
    "print(f\"mAP50: {metrics.box.map50}\")\n",
    "print(f\"Precision: {metrics.box.p}\")\n",
    "print(f\"Recall: {metrics.box.r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.export(format='onnx')  # Export to ONNX format\n",
    "model.save('animal_footprint_detector.pt')  # Save PyTorch model\n",
    "\n",
    "print(\"Training and evaluation complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
